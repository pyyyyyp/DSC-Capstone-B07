{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch_geometric\n",
    "# import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('NCSU-DigIC-GraphData-2023-07-25/xbar/1/xbar.json.gz','rb') as f:\n",
    "    design = json.loads(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = pd.DataFrame(design['instances'])\n",
    "nets = pd.DataFrame(design['nets'])\n",
    "\n",
    "conn=np.load('NCSU-DigIC-GraphData-2023-07-25/xbar/1/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  1,  1, ...,  0,  1,  2],\n",
       "       [ 1, 21,  1, ...,  0,  1,  2],\n",
       "       [ 1,  1, 21, ...,  0,  1,  2],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  5,  0,  0],\n",
       "       [ 1,  1,  1, ...,  0,  5,  2],\n",
       "       [ 2,  2,  2, ...,  0,  2,  5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBST(array,start=0,finish=-1):\n",
    "    if finish<0:\n",
    "        finish = len(array)\n",
    "    mid = (start + finish) // 2\n",
    "    if mid-start==1:\n",
    "        ltl=start\n",
    "    else:\n",
    "        ltl=buildBST(array,start,mid)\n",
    "    \n",
    "    if finish-mid==1:\n",
    "        gtl=mid\n",
    "    else:\n",
    "        gtl=buildBST(array,mid,finish)\n",
    "        \n",
    "    return((array[mid],ltl,gtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "congestion_data = np.load('NCSU-DigIC-GraphData-2023-07-25/xbar/1/xbar_congestion.npz')\n",
    "xbst=buildBST(congestion_data['xBoundaryList'])\n",
    "ybst=buildBST(congestion_data['yBoundaryList'])\n",
    "demand = np.zeros(shape = [instances.shape[0],])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGRCIndex(x,y,xbst,ybst):\n",
    "    while (type(xbst)==tuple):\n",
    "        if x < xbst[0]:\n",
    "            xbst=xbst[1]\n",
    "        else:\n",
    "            xbst=xbst[2]\n",
    "            \n",
    "    while (type(ybst)==tuple):\n",
    "        if y < ybst[0]:\n",
    "            ybst=ybst[1]\n",
    "        else:\n",
    "            ybst=ybst[2]\n",
    "            \n",
    "    return ybst, xbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(instances.shape[0]):\n",
    "#     print(k)\n",
    "    xloc = instances.iloc[k]['xloc']; yloc = instances.iloc[k]['yloc']\n",
    "    i,j=getGRCIndex(xloc,yloc,xbst,ybst)\n",
    "    d = 0 \n",
    "    for l in list(congestion_data['layerList']): \n",
    "        lyr=list(congestion_data['layerList']).index(l)\n",
    "        d += congestion_data['demand'][lyr][i][j]\n",
    "    demand[k] = d\n",
    "        \n",
    "instances['routing_demand'] = demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb2ead32610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCNRegression(nn.Module):\n",
    "#     def __init__(self, nfeat, nhid, dropout):\n",
    "#         super(GCNRegression, self).__init__()\n",
    "\n",
    "#         self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "#         self.gc2 = GraphConvolution(nhid, 1)  # Output layer with 1 unit for regression\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#     def forward(self, x, adj):\n",
    "#         x = F.relu(self.gc1(x, adj))\n",
    "#         x = F.dropout(x, self.dropout, training=self.training)\n",
    "#         x = self.gc2(x, adj)\n",
    "#         return x.squeeze()  # Squeeze the output to have shape (batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNRegressionDynamic(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, dropout, n_layers):\n",
    "        super(GCNRegressionDynamic, self).__init__()\n",
    "\n",
    "        self.gc_layers = nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Input layer\n",
    "        self.gc_layers.append(GraphConvolution(nfeat, nhid))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(n_layers - 2):\n",
    "            self.gc_layers.append(GraphConvolution(nhid, nhid))\n",
    "\n",
    "        # Output layer\n",
    "        self.gc_layers.append(GraphConvolution(nhid, 1))\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        for layer in self.gc_layers[:-1]:\n",
    "            x = F.relu(layer(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        # Output layer without ReLU activation\n",
    "        x = self.gc_layers[-1](x, adj)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    loss_train = nn.MSELoss()(output[idx_train], target[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "                'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                'time: {:.4f}s'.format(time.time() - t))\n",
    "    \n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = nn.MSELoss()(output[idx_test], target[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>xloc</th>\n",
       "      <th>yloc</th>\n",
       "      <th>cell</th>\n",
       "      <th>orient</th>\n",
       "      <th>routing_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clk_gate_out_reg/latch</td>\n",
       "      <td>0</td>\n",
       "      <td>41984</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clk_gate_out_reg_0/latch</td>\n",
       "      <td>1</td>\n",
       "      <td>41984</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clk_gate_out_reg_1/latch</td>\n",
       "      <td>2</td>\n",
       "      <td>44160</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clk_gate_out_reg_2/latch</td>\n",
       "      <td>3</td>\n",
       "      <td>44160</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clk_gate_out_reg_3/latch</td>\n",
       "      <td>4</td>\n",
       "      <td>46336</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>U4123</td>\n",
       "      <td>3947</td>\n",
       "      <td>21888</td>\n",
       "      <td>53760</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>U4125</td>\n",
       "      <td>3948</td>\n",
       "      <td>33664</td>\n",
       "      <td>66048</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>U4128</td>\n",
       "      <td>3949</td>\n",
       "      <td>23296</td>\n",
       "      <td>66048</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>ZCTSBUF_205_132</td>\n",
       "      <td>3950</td>\n",
       "      <td>40576</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>ZCTSBUF_466_133</td>\n",
       "      <td>3951</td>\n",
       "      <td>46848</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3952 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name    id   xloc   yloc  cell  orient  \\\n",
       "0       clk_gate_out_reg/latch     0  41984  44544    23       0   \n",
       "1     clk_gate_out_reg_0/latch     1  41984  47616    23       6   \n",
       "2     clk_gate_out_reg_1/latch     2  44160  44544    23       0   \n",
       "3     clk_gate_out_reg_2/latch     3  44160  47616    23       0   \n",
       "4     clk_gate_out_reg_3/latch     4  46336  47616    23       0   \n",
       "...                        ...   ...    ...    ...   ...     ...   \n",
       "3947                     U4123  3947  21888  53760    42       4   \n",
       "3948                     U4125  3948  33664  66048    42       0   \n",
       "3949                     U4128  3949  23296  66048    34       0   \n",
       "3950           ZCTSBUF_205_132  3950  40576  44544    11       0   \n",
       "3951           ZCTSBUF_466_133  3951  46848  44544    11       6   \n",
       "\n",
       "      routing_demand  \n",
       "0               20.0  \n",
       "1               23.0  \n",
       "2               23.0  \n",
       "3               22.0  \n",
       "4               21.0  \n",
       "...              ...  \n",
       "3947            31.0  \n",
       "3948            30.0  \n",
       "3949            27.0  \n",
       "3950            28.0  \n",
       "3951            23.0  \n",
       "\n",
       "[3952 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2766"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(instances) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = range(2766)\n",
    "idx_test = range(2766, 3952)\n",
    "\n",
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_test = torch.LongTensor(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "nfeat = 4 # Number of input features\n",
    "nhid = 64  # Number of hidden units\n",
    "dropout = 0.2\n",
    "n_layers = 1\n",
    "model = GCNRegressionDynamic(nfeat, nhid, dropout, n_layers) #GCNRegression(nfeat, nhid, dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Loss function for regression (Mean Squared Error)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = instances[['xloc', 'yloc', 'cell', 'orient']].to_numpy()\n",
    "features = sp.csr_matrix(features, dtype=np.float32)\n",
    "features = normalize(features)\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "# features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "\n",
    "target = instances[['routing_demand']].to_numpy()\n",
    "target = torch.tensor(target, dtype=torch.float32).squeeze()\n",
    "\n",
    "adj = normalize(sp.csr_matrix(A, dtype=np.float32))\n",
    "adj = torch.tensor(adj.toarray(), dtype=torch.float32) # adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Epoch: 0010 loss_train: 553.5036 time: 0.1089s\n",
      "Epoch: 0020 loss_train: 471.6997 time: 0.1086s\n",
      "Epoch: 0030 loss_train: 380.0551 time: 0.1087s\n",
      "Epoch: 0040 loss_train: 279.0865 time: 0.1089s\n",
      "Epoch: 0050 loss_train: 184.3705 time: 0.1118s\n",
      "Epoch: 0060 loss_train: 105.7594 time: 0.1088s\n",
      "Epoch: 0070 loss_train: 55.2399 time: 0.1090s\n",
      "Epoch: 0080 loss_train: 30.4675 time: 0.1087s\n",
      "Epoch: 0090 loss_train: 24.3788 time: 0.1096s\n",
      "Epoch: 0100 loss_train: 24.8498 time: 0.1092s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 11.1837s\n",
      "k = 2\n",
      "Epoch: 0010 loss_train: 585.0478 time: 0.1103s\n",
      "Epoch: 0020 loss_train: 498.1251 time: 0.1103s\n",
      "Epoch: 0030 loss_train: 401.3047 time: 0.1089s\n",
      "Epoch: 0040 loss_train: 299.0484 time: 0.1093s\n",
      "Epoch: 0050 loss_train: 199.8082 time: 0.1089s\n",
      "Epoch: 0060 loss_train: 118.5662 time: 0.1098s\n",
      "Epoch: 0070 loss_train: 63.4638 time: 0.1107s\n",
      "Epoch: 0080 loss_train: 34.6123 time: 0.1100s\n",
      "Epoch: 0090 loss_train: 25.2210 time: 0.1104s\n",
      "Epoch: 0100 loss_train: 24.1610 time: 0.1092s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 11.0592s\n",
      "k = 3\n",
      "Epoch: 0010 loss_train: 460.6825 time: 0.2192s\n",
      "Epoch: 0020 loss_train: 156.7155 time: 0.2223s\n",
      "Epoch: 0030 loss_train: 50.6310 time: 0.2213s\n",
      "Epoch: 0040 loss_train: 26.3113 time: 0.2184s\n",
      "Epoch: 0050 loss_train: 30.5062 time: 0.2168s\n",
      "Epoch: 0060 loss_train: 24.7916 time: 0.2173s\n",
      "Epoch: 0070 loss_train: 24.5143 time: 0.2215s\n",
      "Epoch: 0080 loss_train: 24.7325 time: 0.2907s\n",
      "Epoch: 0090 loss_train: 24.4422 time: 0.2194s\n",
      "Epoch: 0100 loss_train: 24.9554 time: 0.2759s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.3491s\n",
      "k = 4\n",
      "Epoch: 0010 loss_train: 454.7489 time: 0.3276s\n",
      "Epoch: 0020 loss_train: 66.9277 time: 0.3265s\n",
      "Epoch: 0030 loss_train: 42.4013 time: 0.3262s\n",
      "Epoch: 0040 loss_train: 26.1195 time: 0.3259s\n",
      "Epoch: 0050 loss_train: 25.8539 time: 0.3295s\n",
      "Epoch: 0060 loss_train: 24.3355 time: 0.3262s\n",
      "Epoch: 0070 loss_train: 25.0774 time: 0.3267s\n",
      "Epoch: 0080 loss_train: 24.9335 time: 0.3268s\n",
      "Epoch: 0090 loss_train: 24.8337 time: 0.3291s\n",
      "Epoch: 0100 loss_train: 24.8634 time: 0.3336s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 32.9205s\n",
      "k = 5\n",
      "Epoch: 0010 loss_train: 254.2021 time: 0.4361s\n",
      "Epoch: 0020 loss_train: 25.8209 time: 0.4410s\n",
      "Epoch: 0030 loss_train: 26.8850 time: 0.4371s\n",
      "Epoch: 0040 loss_train: 26.5767 time: 0.4359s\n",
      "Epoch: 0050 loss_train: 25.8274 time: 0.4376s\n",
      "Epoch: 0060 loss_train: 26.1945 time: 0.4358s\n",
      "Epoch: 0070 loss_train: 24.4234 time: 0.4353s\n",
      "Epoch: 0080 loss_train: 25.3876 time: 0.4516s\n",
      "Epoch: 0090 loss_train: 25.8000 time: 0.4460s\n",
      "Epoch: 0100 loss_train: 25.1761 time: 0.4353s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 44.0607s\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=['Layer', 'Test_MSE', 'Time'])\n",
    "\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    print(\"k = {layer}\".format(layer=i))\n",
    "    \n",
    "    # Modify your model creation and training based on the layer number (i)\n",
    "    model = GCNRegressionDynamic(nfeat, nhid, dropout, i)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    t_total = time.time()\n",
    "    for epoch in range(100):\n",
    "        train(epoch)\n",
    "    elapsed_time = time.time() - t_total\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(elapsed_time))\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = nn.MSELoss()(output[idx_test], target[idx_test])\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    results_df = results_df.append({'Layer': i, 'Test_MSE': loss_test.item(), 'Time': elapsed_time}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Test_MSE</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.384588</td>\n",
       "      <td>11.183727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.480188</td>\n",
       "      <td>11.059214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.794757</td>\n",
       "      <td>22.349082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.860625</td>\n",
       "      <td>32.920534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.975776</td>\n",
       "      <td>44.060694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Layer   Test_MSE       Time\n",
       "0    1.0  12.384588  11.183727\n",
       "1    2.0  12.480188  11.059214\n",
       "2    3.0  12.794757  22.349082\n",
       "3    4.0  12.860625  32.920534\n",
       "4    5.0  12.975776  44.060694"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addiing an attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        att_weights = F.softmax(torch.mm(input, self.weight), dim=1)\n",
    "        output = att_weights * input\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "class GCNAttentionDynamic(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, dropout, n_layers):\n",
    "        super(GCNAttentionDynamic, self).__init__()\n",
    "\n",
    "        self.gc_layers = nn.ModuleList()\n",
    "        self.att_layers = nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Input layer\n",
    "        self.gc_layers.append(GraphConvolution(nfeat, nhid))\n",
    "        self.att_layers.append(AttentionLayer(nhid, nhid))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(n_layers - 2):\n",
    "            self.gc_layers.append(GraphConvolution(nhid, nhid))\n",
    "            self.att_layers.append(AttentionLayer(nhid, nhid))\n",
    "\n",
    "        # Output layer\n",
    "        self.gc_layers.append(GraphConvolution(nhid, 1))\n",
    "        self.att_layers.append(AttentionLayer(1, 1))\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        for gc_layer, att_layer in zip(self.gc_layers[:-1], self.att_layers[:-1]):\n",
    "            x = F.relu(gc_layer(x, adj))\n",
    "            x = att_layer(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        # Output layer without ReLU activation\n",
    "        x = self.gc_layers[-1](x, adj)\n",
    "        x = self.att_layers[-1](x)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss_train: 631.8388 time: 0.1279s\n",
      "Epoch: 0020 loss_train: 558.8183 time: 0.1107s\n",
      "Epoch: 0030 loss_train: 474.3437 time: 0.1106s\n",
      "Epoch: 0040 loss_train: 374.0381 time: 0.1108s\n",
      "Epoch: 0050 loss_train: 269.6749 time: 0.1108s\n",
      "Epoch: 0060 loss_train: 175.6591 time: 0.1106s\n",
      "Epoch: 0070 loss_train: 101.1636 time: 0.1113s\n",
      "Epoch: 0080 loss_train: 53.4536 time: 0.1105s\n",
      "Epoch: 0090 loss_train: 30.4796 time: 0.1109s\n",
      "Epoch: 0100 loss_train: 25.1042 time: 0.1106s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 11.2215s\n"
     ]
    }
   ],
   "source": [
    "# original GCN\n",
    "model = GCNRegressionDynamic(nfeat, nhid, dropout, 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "t_total = time.time()\n",
    "for epoch in range(100):\n",
    "    train(epoch)\n",
    "elapsed_time = time.time() - t_total\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(elapsed_time))\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "output = model(features, adj)\n",
    "loss_test_GCN = nn.MSELoss()(output[idx_test], target[idx_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss_train: 580.4120 time: 0.1262s\n",
      "Epoch: 0020 loss_train: 488.3988 time: 0.1152s\n",
      "Epoch: 0030 loss_train: 394.4220 time: 0.1152s\n",
      "Epoch: 0040 loss_train: 297.7288 time: 0.1151s\n",
      "Epoch: 0050 loss_train: 206.7276 time: 0.1162s\n",
      "Epoch: 0060 loss_train: 129.6535 time: 0.1150s\n",
      "Epoch: 0070 loss_train: 72.4829 time: 0.1162s\n",
      "Epoch: 0080 loss_train: 40.5150 time: 0.1151s\n",
      "Epoch: 0090 loss_train: 26.9751 time: 0.1152s\n",
      "Epoch: 0100 loss_train: 23.9305 time: 0.1161s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 11.7538s\n"
     ]
    }
   ],
   "source": [
    "# GCN with attention\n",
    "model = GCNAttentionDynamic(nfeat, nhid, dropout, 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "t_total = time.time()\n",
    "for epoch in range(100):\n",
    "    train(epoch)\n",
    "elapsed_time = time.time() - t_total\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(elapsed_time))\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "output = model(features, adj)\n",
    "loss_test_attention = nn.MSELoss()(output[idx_test], target[idx_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Test loss = 13.634328842163086, GCN Test loss with attention layer = 12.835390090942383\n"
     ]
    }
   ],
   "source": [
    "print(\"GCN Test loss = {GCN}, GCN Test loss with attention layer = {att}\".format(GCN = loss_test_GCN, att = loss_test_attention))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize an empty adjacency matrix\n",
    "# adj_matrix = None\n",
    "\n",
    "# # Initialize an empty adjacency matrix\n",
    "# total_rows = 0  # You might need to adjust this based on your data\n",
    "# total_cols = 0  # You might need to adjust this based on your data\n",
    "# adj_matrix = coo_matrix((total_rows, total_cols), dtype=np.int32)\n",
    "\n",
    "# # Loop through the files\n",
    "# for i in range(1, 3):\n",
    "#     file_path = f'NCSU-DigIC-GraphData-2023-07-25/xbar/{i}/xbar_connectivity.npz'\n",
    "#     conn = np.load(file_path)\n",
    "\n",
    "#     # Update the adjacency matrix with the current file's data\n",
    "#     current_matrix = coo_matrix((conn['data'], (conn['row']+ total_rows, conn['col']+total_cols)), shape=[total_rows, total_cols])\n",
    "    \n",
    "#     if adj_matrix is None:\n",
    "#         adj_matrix = current_matrix\n",
    "#     else:\n",
    "#         # Check and adjust the shape if necessary\n",
    "#         total_rows = max(adj_matrix.shape[0], current_matrix.shape[0])\n",
    "#         total_cols = max(adj_matrix.shape[1], current_matrix.shape[1])\n",
    "#         adj_matrix.resize((total_rows, total_cols))\n",
    "        \n",
    "#         # Add the current matrix to the adjacency matrix\n",
    "#         adj_matrix += current_matrix\n",
    "\n",
    "# # Convert the final adjacency matrix to a dense format if needed\n",
    "# adj_matrix = adj_matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training files, load xbar 2 as testing\n",
    "with gzip.open('NCSU-DigIC-GraphData-2023-07-25/xbar/2/xbar.json.gz','rb') as f:\n",
    "    design = json.loads(f.read().decode('utf-8'))\n",
    "\n",
    "instances = pd.DataFrame(design['instances'])\n",
    "nets = pd.DataFrame(design['nets'])\n",
    "\n",
    "conn=np.load('NCSU-DigIC-GraphData-2023-07-25/xbar/2/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)\n",
    "\n",
    "congestion_data = np.load('NCSU-DigIC-GraphData-2023-07-25/xbar/2/xbar_congestion.npz')\n",
    "xbst=buildBST(congestion_data['xBoundaryList'])\n",
    "ybst=buildBST(congestion_data['yBoundaryList'])\n",
    "demand = np.zeros(shape = [instances.shape[0],])\n",
    "\n",
    "for k in range(instances.shape[0]):\n",
    "#     print(k)\n",
    "    xloc = instances.iloc[k]['xloc']; yloc = instances.iloc[k]['yloc']\n",
    "    i,j=getGRCIndex(xloc,yloc,xbst,ybst)\n",
    "    d = 0 \n",
    "    for l in list(congestion_data['layerList']): \n",
    "        lyr=list(congestion_data['layerList']).index(l)\n",
    "        d += congestion_data['demand'][lyr][i][j]\n",
    "    demand[k] = d\n",
    "        \n",
    "instances['routing_demand'] = demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = instances[['xloc', 'yloc', 'cell', 'orient']].to_numpy()\n",
    "features = sp.csr_matrix(features, dtype=np.float32)\n",
    "features = normalize(features)\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "# features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "\n",
    "target = instances[['routing_demand']].to_numpy()\n",
    "target = torch.tensor(target, dtype=torch.float32).squeeze()\n",
    "\n",
    "adj = normalize(sp.csr_matrix(A, dtype=np.float32))\n",
    "adj = torch.tensor(adj.toarray(), dtype=torch.float32) # adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(188.0422, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "output = model(features, adj)\n",
    "nn.MSELoss()(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
