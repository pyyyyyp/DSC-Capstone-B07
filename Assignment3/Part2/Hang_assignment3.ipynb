{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this file is given by instructor\n",
    "#used for extracting routing demand\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "with gzip.open('xbar/1/xbar.json.gz','rb') as f:\n",
    "    design = json.loads(f.read().decode('utf-8'))\n",
    "    \n",
    "instances = pd.DataFrame(design['instances'])\n",
    "nets = pd.DataFrame(design['nets'])\n",
    "\n",
    "conn=np.load('xbar/1/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)\n",
    "\n",
    "def buildBST(array,start=0,finish=-1):\n",
    "    if finish<0:\n",
    "        finish = len(array)\n",
    "    mid = (start + finish) // 2\n",
    "    if mid-start==1:\n",
    "        ltl=start\n",
    "    else:\n",
    "        ltl=buildBST(array,start,mid)\n",
    "    \n",
    "    if finish-mid==1:\n",
    "        gtl=mid\n",
    "    else:\n",
    "        gtl=buildBST(array,mid,finish)\n",
    "        \n",
    "    return((array[mid],ltl,gtl))\n",
    "\n",
    "congestion_data = np.load('xbar/1/xbar_congestion.npz')\n",
    "xbst=buildBST(congestion_data['xBoundaryList'])\n",
    "ybst=buildBST(congestion_data['yBoundaryList'])\n",
    "demand = np.zeros(shape = [instances.shape[0],])\n",
    "\n",
    "\n",
    "def getGRCIndex(x,y,xbst,ybst):\n",
    "    while (type(xbst)==tuple):\n",
    "        if x < xbst[0]:\n",
    "            xbst=xbst[1]\n",
    "        else:\n",
    "            xbst=xbst[2]\n",
    "            \n",
    "    while (type(ybst)==tuple):\n",
    "        if y < ybst[0]:\n",
    "            ybst=ybst[1]\n",
    "        else:\n",
    "            ybst=ybst[2]\n",
    "            \n",
    "    return ybst, xbst\n",
    "\n",
    "\n",
    "for k in range(instances.shape[0]):\n",
    "    xloc = instances.iloc[k]['xloc']; yloc = instances.iloc[k]['yloc']\n",
    "    i,j=getGRCIndex(xloc,yloc,xbst,ybst)\n",
    "    d = 0 \n",
    "    for l in list(congestion_data['layerList']): \n",
    "        lyr=list(congestion_data['layerList']).index(l)\n",
    "        d += congestion_data['demand'][lyr][i][j]\n",
    "    demand[k] = d\n",
    "        \n",
    "instances['routing_demand'] = demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xloc</th>\n",
       "      <th>yloc</th>\n",
       "      <th>cell</th>\n",
       "      <th>orient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41984</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41984</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44160</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44160</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46336</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>21888</td>\n",
       "      <td>53760</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>33664</td>\n",
       "      <td>66048</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>23296</td>\n",
       "      <td>66048</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>40576</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>46848</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3952 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xloc   yloc  cell  orient\n",
       "0     41984  44544    23       0\n",
       "1     41984  47616    23       6\n",
       "2     44160  44544    23       0\n",
       "3     44160  47616    23       0\n",
       "4     46336  47616    23       0\n",
       "...     ...    ...   ...     ...\n",
       "3947  21888  53760    42       4\n",
       "3948  33664  66048    42       0\n",
       "3949  23296  66048    34       0\n",
       "3950  40576  44544    11       0\n",
       "3951  46848  44544    11       6\n",
       "\n",
       "[3952 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#excluding irrelevant and meaning-less columns\n",
    "df = instances.drop(columns=['name', 'id'], axis=1)\n",
    "df[['xloc', 'yloc', 'cell', 'orient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 1 layers - MSE: 80.82246398925781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 2 layers - MSE: 461.6094055175781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 3 layers - MSE: 41996164.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 4 layers - MSE: 4518.43212890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 5 layers - MSE: 1.0377233893063818e+24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#set seed for repetitive test\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "#extrating the adjacency matrix\n",
    "conn=np.load('xbar/1/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)\n",
    "A = torch.FloatTensor(np.array(A.todense()))\n",
    "\n",
    "#set target y\n",
    "target_values = df['routing_demand'] \n",
    "\n",
    "#split train/test dataset\n",
    "train_size = 0.7\n",
    "indices = np.arange(len(target_values))\n",
    "train_indices, test_indices = train_test_split(indices, train_size=train_size, random_state=seed)\n",
    "\n",
    "#feature engineering\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(df[['xloc', 'yloc', 'cell', 'orient']]) \n",
    "\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(target_values)\n",
    "\n",
    "input_size = features.shape[1]\n",
    "output_size = 1\n",
    "\n",
    "#build GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, hidden_size)])\n",
    "        self.layers.extend([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        for layer in self.layers:\n",
    "            x = torch.relu(layer(x))\n",
    "            x = torch.spmm(A, x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "hidden_size = 20\n",
    "num_layers_list = [1, 2, 3, 4, 5]\n",
    "learning_rate = 0.02\n",
    "num_epochs = 1000\n",
    "\n",
    "for num_layers in num_layers_list:\n",
    "    model = GCN(input_size, hidden_size, output_size, num_layers)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        outputs = model(features, A)\n",
    "        loss = criterion(outputs[train_indices], targets[train_indices])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(features, A)\n",
    "        mse = mean_squared_error(test_outputs[test_indices].numpy(), targets[test_indices].numpy())\n",
    "\n",
    "    print(f\"Performance for {num_layers} layers - MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION GCN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 1 layers - MSE: 80.07828521728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 2 layers - MSE: 6315.73779296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 3 layers - MSE: 214667056.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 4 layers - MSE: 1970.515380859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/cse150b/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2766])) that is different to the input size (torch.Size([2766, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for 5 layers - MSE: 8.261854236987115e+23\n"
     ]
    }
   ],
   "source": [
    "#copy paste from the above section except for GCN model where added an extra attention.\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "conn=np.load('xbar/1/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)\n",
    "A = torch.FloatTensor(np.array(A.todense()))\n",
    "\n",
    "target_values = df['routing_demand']  \n",
    "\n",
    "train_size = 0.7\n",
    "indices = np.arange(len(target_values))\n",
    "train_indices, test_indices = train_test_split(indices, train_size=train_size, random_state=seed)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(df[['xloc', 'yloc', 'cell', 'orient']]) \n",
    "\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(target_values)\n",
    "\n",
    "\n",
    "input_size = features.shape[1]\n",
    "output_size = 1 \n",
    "\n",
    "class AttentionGCN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        #added attention layer here\n",
    "        super(AttentionGCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, hidden_size)])\n",
    "        self.layers.extend([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.attention_weights = nn.Parameter(torch.rand(num_layers))\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        for layer_idx, layer in enumerate(self.layers):\n",
    "            x = torch.relu(layer(x))\n",
    "            attention_weight = F.softmax(self.attention_weights[layer_idx], dim=0)\n",
    "            x = attention_weight * torch.spmm(A, x) + x \n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_size = 20\n",
    "num_layers_list = [1, 2, 3, 4, 5]\n",
    "learning_rate = 0.02\n",
    "num_epochs = 1000\n",
    "\n",
    "for num_layers in num_layers_list:\n",
    "    model = AttentionGCN(input_size, hidden_size, output_size, num_layers)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        outputs = model(features, A)\n",
    "        loss = criterion(outputs[train_indices], targets[train_indices])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(features, A)\n",
    "        mse = mean_squared_error(test_outputs[test_indices].numpy(), targets[test_indices].numpy())\n",
    "\n",
    "    print(f\"Performance for {num_layers} layers - MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "conn = np.load('xbar/1/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)\n",
    "A = torch.FloatTensor(np.array(A.todense()))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(df[['xloc', 'yloc', 'cell', 'orient']])\n",
    "\n",
    "features = torch.FloatTensor(features)\n",
    "targets = torch.FloatTensor(df['routing_demand'])\n",
    "\n",
    "input_size = features.shape[1]\n",
    "output_size = 1  # Regression task\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, hidden_size)])\n",
    "        self.layers.extend([nn.Linear(hidden_size, hidden_size) for _ in range(num_layers - 1)])\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        for layer in self.layers:\n",
    "            x = torch.relu(layer(x))\n",
    "            x = torch.spmm(A, x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "hidden_size = 20\n",
    "num_layers = 1\n",
    "learning_rate = 0.02\n",
    "num_epochs = 1000\n",
    "\n",
    "total_samples = len(df)\n",
    "mse_results = []\n",
    "\n",
    "#for loop for loading all different folders.\n",
    "for i in range(total_samples):\n",
    "    train_indices = np.arange(total_samples)\n",
    "    train_indices = np.delete(train_indices, i)\n",
    "    test_indices = [i]\n",
    "\n",
    "    model = GCN(input_size, hidden_size, output_size, num_layers)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(features[train_indices], A)\n",
    "        loss = criterion(outputs, targets[train_indices])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(features[test_indices], A)\n",
    "        mse = mean_squared_error(test_outputs.numpy(), targets[test_indices].numpy())\n",
    "        mse_results.append(mse)\n",
    "\n",
    "average_mse = np.mean(mse_results)\n",
    "print(f\"Average MSE across leave-one-out experiments: {average_mse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse150b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
